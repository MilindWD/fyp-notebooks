{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Word2Vec-Sentiment140-DNN.ipynb","provenance":[{"file_id":"1rCVqAMCluODlCszRJwX8HqO6w15L95Hp","timestamp":1652899090550}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"daF4m6dhRC5U"},"outputs":[],"source":["from gensim.models import KeyedVectors"]},{"cell_type":"code","source":["w2v=KeyedVectors.load(\"/content/drive/MyDrive/comparative_Analysis_of_embeddings/Sentiment140/Word2Vec/w2c\")"],"metadata":{"id":"avSShh_dTqU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","df=pd.read_csv(\"/content/drive/MyDrive/comparative_Analysis_of_embeddings/Sentiment140/sentiment140-subset-preprocessed.csv\")\n","y=df[\"polarity\"]\n"],"metadata":{"id":"YdRTuzIsRhQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["maxi=-1\n","for i,rev in enumerate(df['new_text']):\n","  tokens=rev.split()\n","  if(len(tokens)>maxi):\n","    maxi=len(tokens)\n","print(maxi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9smlOnLRhzi","executionInfo":{"status":"ok","timestamp":1652073155752,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sharath H N","userId":"13262199813391015497"}},"outputId":"8a9fbc2d-6ca2-4bf5-bf1e-71e7ea0927af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["65\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","maxlen=66\n","max_words=len(w2v.wv.vocab.keys())\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words)\n","def padded_sequence(X):\n","  tokenizer.fit_on_texts(X)\n","  sequences = tokenizer.texts_to_sequences(X)\n","  data = pad_sequences(sequences, maxlen=maxlen)\n","  return data\n","X=padded_sequence(df[\"new_text\"])\n","X"],"metadata":{"id":"3E_9bs0mR2if","executionInfo":{"status":"ok","timestamp":1652073161025,"user_tz":-330,"elapsed":5281,"user":{"displayName":"Sharath H N","userId":"13262199813391015497"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a43da8e8-929f-42d2-e4af-b546a588369d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0,     0,     0, ...,    12,     9,    72],\n","       [    0,     0,     0, ...,   137,    14,  2628],\n","       [    0,     0,     0, ...,     7,   116,  4375],\n","       ...,\n","       [    0,     0,     0, ...,  4583,   318, 11391],\n","       [    0,     0,     0, ...,     0,  9807,   449],\n","       [    0,     0,     0, ...,     1,    52, 95570]], dtype=int32)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["import numpy as np\n","embed_matrix=np.zeros(shape=(max_words,300))\n","for word,i in tokenizer.word_index.items():\n","  if word in w2v:\n","    embed_vector=w2v[word]\n","  # word is in the vocabulary learned by the w2v model\n","    embed_matrix[i]=embed_vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5i3OxrxUMpp","executionInfo":{"status":"ok","timestamp":1652073162804,"user_tz":-330,"elapsed":1797,"user":{"displayName":"Sharath H N","userId":"13262199813391015497"}},"outputId":"e3190b5b-9ffd-4251-fd0e-596afed20e72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  \"\"\"\n"]}]},{"cell_type":"code","source":["embed_matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4KOA226UkWU","executionInfo":{"status":"ok","timestamp":1652017921479,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sharath H N","userId":"13262199813391015497"}},"outputId":"082d69ff-b6be-4089-a2a7-15789ce8a914"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.72822678,  0.7488817 , -1.08043909, ...,  0.63756752,\n","         0.96165609, -0.1680413 ],\n","       [-1.78625202,  1.72100365, -1.29291737, ...,  0.59565586,\n","        -0.29386473,  1.10913849],\n","       ...,\n","       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n","         0.        ,  0.        ]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"],"metadata":{"id":"RCSaE9FSU9Tt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.initializers import Constant\n","from tensorflow.keras.layers import ReLU\n","from tensorflow.keras.layers import Dropout,Embedding,GRU,Dense,Flatten\n","model=Sequential()\n","model.add(Embedding(input_dim=max_words,output_dim=300,input_length=66,embeddings_initializer=Constant(embed_matrix)))\n","model.add(Flatten()) # loss stucks at about \n","model.add(Dense(32,activation='relu'))\n","model.add(Dropout(0.60))\n","model.add(Dense(16,activation='relu'))\n","model.add(Dropout(0.60))\n","model.add(Dense(1,activation='sigmoid'))"],"metadata":{"id":"Lx__DKK0XfCP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcERRc5uYXSS","executionInfo":{"status":"ok","timestamp":1652074389423,"user_tz":-330,"elapsed":1223167,"user":{"displayName":"Sharath H N","userId":"13262199813391015497"}},"outputId":"3c9a1b47-aaf7-493a-c795-ade7a6f29c82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1172/1172 [==============================] - 20s 12ms/step - loss: 0.6548 - accuracy: 0.5988\n","Epoch 2/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.5961 - accuracy: 0.6752\n","Epoch 3/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.5503 - accuracy: 0.7232\n","Epoch 4/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.5091 - accuracy: 0.7569\n","Epoch 5/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.4703 - accuracy: 0.7860\n","Epoch 6/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.4347 - accuracy: 0.8060\n","Epoch 7/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.3992 - accuracy: 0.8215\n","Epoch 8/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.3669 - accuracy: 0.8384\n","Epoch 9/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.3344 - accuracy: 0.8535\n","Epoch 10/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.3079 - accuracy: 0.8645\n","Epoch 11/100\n","1172/1172 [==============================] - 12s 11ms/step - loss: 0.2791 - accuracy: 0.8773\n","Epoch 12/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.2570 - accuracy: 0.8851\n","Epoch 13/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.2350 - accuracy: 0.8946\n","Epoch 14/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.2183 - accuracy: 0.9026\n","Epoch 15/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.2033 - accuracy: 0.9092\n","Epoch 16/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1893 - accuracy: 0.9136\n","Epoch 17/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1768 - accuracy: 0.9201\n","Epoch 18/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1615 - accuracy: 0.9255\n","Epoch 19/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1557 - accuracy: 0.9279\n","Epoch 20/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1459 - accuracy: 0.9328\n","Epoch 21/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1381 - accuracy: 0.9355\n","Epoch 22/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1312 - accuracy: 0.9387\n","Epoch 23/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1265 - accuracy: 0.9409\n","Epoch 24/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1196 - accuracy: 0.9434\n","Epoch 25/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1144 - accuracy: 0.9467\n","Epoch 26/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1100 - accuracy: 0.9477\n","Epoch 27/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1040 - accuracy: 0.9503\n","Epoch 28/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.1012 - accuracy: 0.9519\n","Epoch 29/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0958 - accuracy: 0.9537\n","Epoch 30/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0927 - accuracy: 0.9555\n","Epoch 31/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0878 - accuracy: 0.9585\n","Epoch 32/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0866 - accuracy: 0.9579\n","Epoch 33/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0804 - accuracy: 0.9601\n","Epoch 34/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0804 - accuracy: 0.9607\n","Epoch 35/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0753 - accuracy: 0.9633\n","Epoch 36/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0730 - accuracy: 0.9644\n","Epoch 37/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0676 - accuracy: 0.9658\n","Epoch 38/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0662 - accuracy: 0.9671\n","Epoch 39/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0658 - accuracy: 0.9672\n","Epoch 40/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0620 - accuracy: 0.9685\n","Epoch 41/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0592 - accuracy: 0.9695\n","Epoch 42/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0592 - accuracy: 0.9701\n","Epoch 43/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0557 - accuracy: 0.9717\n","Epoch 44/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0557 - accuracy: 0.9709\n","Epoch 45/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0548 - accuracy: 0.9720\n","Epoch 46/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0523 - accuracy: 0.9735\n","Epoch 47/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0505 - accuracy: 0.9736\n","Epoch 48/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0477 - accuracy: 0.9755\n","Epoch 49/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0464 - accuracy: 0.9749\n","Epoch 50/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0454 - accuracy: 0.9762\n","Epoch 51/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0449 - accuracy: 0.9765\n","Epoch 52/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0440 - accuracy: 0.9770\n","Epoch 53/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0420 - accuracy: 0.9780\n","Epoch 54/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0410 - accuracy: 0.9786\n","Epoch 55/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0407 - accuracy: 0.9783\n","Epoch 56/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0390 - accuracy: 0.9797\n","Epoch 57/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0391 - accuracy: 0.9794\n","Epoch 58/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0378 - accuracy: 0.9795\n","Epoch 59/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0377 - accuracy: 0.9805\n","Epoch 60/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0362 - accuracy: 0.9807\n","Epoch 61/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0340 - accuracy: 0.9814\n","Epoch 62/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0349 - accuracy: 0.9817\n","Epoch 63/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0325 - accuracy: 0.9827\n","Epoch 64/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0327 - accuracy: 0.9824\n","Epoch 65/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0322 - accuracy: 0.9827\n","Epoch 66/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0323 - accuracy: 0.9831\n","Epoch 67/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0300 - accuracy: 0.9838\n","Epoch 68/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0304 - accuracy: 0.9841\n","Epoch 69/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0297 - accuracy: 0.9838\n","Epoch 70/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0303 - accuracy: 0.9841\n","Epoch 71/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0290 - accuracy: 0.9840\n","Epoch 72/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0289 - accuracy: 0.9845\n","Epoch 73/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0281 - accuracy: 0.9846\n","Epoch 74/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0271 - accuracy: 0.9857\n","Epoch 75/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0271 - accuracy: 0.9856\n","Epoch 76/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0265 - accuracy: 0.9863\n","Epoch 77/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0271 - accuracy: 0.9850\n","Epoch 78/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0251 - accuracy: 0.9864\n","Epoch 79/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0258 - accuracy: 0.9867\n","Epoch 80/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0253 - accuracy: 0.9866\n","Epoch 81/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0243 - accuracy: 0.9869\n","Epoch 82/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0235 - accuracy: 0.9868\n","Epoch 83/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0234 - accuracy: 0.9876\n","Epoch 84/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0250 - accuracy: 0.9867\n","Epoch 85/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0242 - accuracy: 0.9871\n","Epoch 86/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0232 - accuracy: 0.9877\n","Epoch 87/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0236 - accuracy: 0.9872\n","Epoch 88/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0217 - accuracy: 0.9882\n","Epoch 89/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0244 - accuracy: 0.9874\n","Epoch 90/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0217 - accuracy: 0.9882\n","Epoch 91/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0232 - accuracy: 0.9879\n","Epoch 92/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0213 - accuracy: 0.9880\n","Epoch 93/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0215 - accuracy: 0.9882\n","Epoch 94/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0216 - accuracy: 0.9882\n","Epoch 95/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0201 - accuracy: 0.9890\n","Epoch 96/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0216 - accuracy: 0.9885\n","Epoch 97/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0202 - accuracy: 0.9893\n","Epoch 98/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0210 - accuracy: 0.9885\n","Epoch 99/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0212 - accuracy: 0.9882\n","Epoch 100/100\n","1172/1172 [==============================] - 12s 10ms/step - loss: 0.0216 - accuracy: 0.9885\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f40bc906890>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["y_pred=model.predict(X_test)\n","for i in range(len(y_pred)):\n","  if y_pred[i]>0.5:\n","    y_pred[i]=1\n","  else:\n","    y_pred[i]=0"],"metadata":{"id":"1vbZvYwbY-Ta"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Metric calculation function\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","def display_metrics(y_test,y_pred):\n","    print(accuracy_score(y_test, y_pred))\n","    print(f1_score(y_test, y_pred, average=\"macro\"))\n","    print(precision_score(y_test, y_pred, average=\"macro\"))\n","    print(recall_score(y_test, y_pred, average=\"macro\"))\n","display_metrics(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJqBbR0SdxM8","executionInfo":{"status":"ok","timestamp":1652075041091,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sharath H N","userId":"13262199813391015497"}},"outputId":"7754c3e6-c014-499d-8e52-41050c6e2b1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.73196\n","0.7319486050279793\n","0.732044440495619\n","0.7319865855272287\n"]}]}]}